---
title: 'Final Assignment: Predicting Director Compensation'
author: "Jasper Ginn (s6100848)"
date: "April 8, 2019"
output:
  pdf_document: 
    number_sections: false
header-includes:
 \usepackage{float}
 \usepackage{setspace}
 \usepackage{xcolor}
 \definecolor{mypurple}{rgb}{146,76,239}
 \singlespacing
 \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.pos="H", fig.width = 7, fig.height = 4, echo = FALSE, 
                      fig.align="center", warning = FALSE, message = FALSE, eval=FALSE)

rm(list=ls())

# Load blm package
library(blm)

# Load ggplot
library(ggplot2)
library(gridExtra)

# Get the directors data
data("directors")

# Preprocess directors data
library(dplyr)
directors <- directors %>%
  # Log compensation
  mutate(Compensation = log(Compensation)) %>%
  # Subtract mean from Age variable
  mutate(Age = Age - mean(Age),
         Male = as.numeric(Male) - mean(as.numeric(Male)))

# Define a convenience function. Basically, take nice output from a stargazer latex regression table & modify it for blm models.
```

```{r julia setup}
# Set up blm julia
blm_setup() 
```

# Introduction

$$
\tag{1}
\hat{\log(\text{compensation}_i)} = \beta_0 + \beta_{1} \text{age}_i + \beta_2\text{male}_i + \beta_3\text{SectorServices}_i + \beta_4\text{SectorBasicMaterials}_i + \epsilon_i
$$

```{r model1, include = FALSE}
## Run two models.

# Model 1: only age and male dummy ==> baseline model -----

# Priors are uninformative (mean 0, sd 1000)
# Initial values are drawn from the priors
dirmod1 <- blm("Compensation ~ Age + Male",
                    data=directors) %>%
  # Set sampling options
  set_sampling_options(chains = 2, iterations = 30000,
                       burn = 8000, thinning=3) %>%
  # Set initial values
  set_initial_values(chain_1 = list("b" = c(7, -5, 0), "sigma" = 1),
                     chain_2 = list("b" = c(-5, 0, 7), "sigma" = 2)) %>%
  # Sample
  sample_posterior() %>%
  # Compute posterior predictive checks (using a random sample of 20% of the data)
  evaluate_ppc(p=0.2)
# Sanity check for coefficients
coef(dirmod1)
coef(lm("Compensation ~ Age + Male", data=directors)) # Sanity check
# Inspect convergence
dirmod1 %>%
  evaluate_convergence_diagnostics() # OK

# Plots
plot(dirmod1, "history")
plot(dirmod1, "density")
plot(dirmod1, "autocorrelation") # OK

# Summary
summary(dirmod1)
# ==> neither male nor age is a predictor of logged compensation (CCI contains 0)

# Plot
dirmod1 %>% 
  get_value("rsq") %>%
  plot()

# Summary of ppc
dirmod1 %>%
  get_value("ppc") %>%
  summary() # Vio;lating independence

# Plot results of the ppc
p1 <- plot(dirmod1 %>% 
            get_value("ppc"), 
          "normality") # Two-sided test ==> violation 
p2 <- plot(dirmod1 %>% 
            get_value("ppc"), 
          "heteroskedasticity") # One-sided test ==> violation (data are more heteroskedastic)
p3 <- plot(dirmod1 %>%
            get_value("ppc"), 
          "independence") # Two-sided test ==> violation (data are correlated)

# Plot
grid.arrange(p1, p2, p3, ncol=3)
```

```{r ppc results}
dirmod1 %>%
  get_value("ppc") %>%
  get_value("data") %>%
  .$independence %>%
  apply(2, mean)
```

From the PPC plots, we see that the data are violating the assumption of independence as the MAP of the correlation coefficient for the observed data indicates a strong positive correlation $(\hat{r}_{\text{MAP, PPC}} = .466)$.

```{r model2, include = FALSE}
# Model 2: Age, gender and sector -----

# Hypothesis: the relationship between gender and compensation differs across sectors
# We have three: financial (base case), services and Basic materials

# Create the model
dirmod2 <- blm("Compensation ~ Sector + Age + Male",
                data=directors) 

# Retrieve parameter names
dirmod2 %>% get_parameter_names()

# Update the model specification
dirmod2 <- dirmod2 %>%
  # Need to delete posterior when we change settings
  # (only has an effect if posterior already present)
  delete_posterior() %>%
  # Set an informative prior on the coefficients
  # Male (b4) is speculated to have 17% pay increase over women
  set_prior("b4", mu = .17, sd=0.01) %>%
  # Change the sampler of Age to metropolis hastings
  # Lambda parameter controls the variance of the (normal) proposal distribution
  set_sampler("b3", type="MH", lambda=0.01) %>%
  # Update sampling settings
  set_sampling_options(chains = 2, iterations = 60000,
                       burn = 15000, thinning=4) %>%
  # Set initial values
  # If we draw from the priors the starting values will be too large
  # This is an issue for MH because it takes many more iterations to converge
  set_initial_values(chain_1 = list("b" = c(4, 2, 3, 8, 10), "sigma"= 1),
                     chain_2 = list("b" = c(2, 4, 7, 2, 3), "sigma"=2)) %>%
  # Sample the posterior distribution
  sample_posterior()

# Compute a z-score difference from the posterior to the prior
# Idea: how much does the posterior shift when confronted with new data?
#        calculate on the scale of the posterior
thprior <- rnorm(1, mean=dirmod2$priors$b4$mu, sd=dirmod2$priors$b4$sd)
ps <- get_posterior_samples(dirmod2) 
pmu <- apply(ps, 2, mean)
psd <- apply(ps, 2, sd)
z <- abs((pmu["Male"] - thprior) / psd["Male"])

# Evaluate the accepted draws
dirmod2 %>% 
  evaluate_accepted_draws() # ~ 40-45%

# Look at burn-in diagnostics
dirmod2 %>% 
  evaluate_convergence_diagnostics()

# Check history plot
plot(dirmod2, "history") # Burn-in is not high enough

# Update burn-in size & draw more samples from the posterior
#dirmod2 <- dirmod2 %>%
#  set_sampling_options(burn = 12000) %>%
#  update_posterior(iterations = 20000)

# Evaluate the accepted draws
dirmod2 %>% evaluate_accepted_draws() # ~ 30%

# Check history
plot(dirmod2, "history") # This seems OK
# Check autocorrelation
plot(dirmod2, "autocorrelation") # Not a problem

# Evaluate the effect of MH on the effective sample size
dirmod2 %>% 
  evaluate_effective_sample_size() 

# View densities
plot(dirmod2, "density")

# Summary
summary(dirmod2)
# ==> Male still not a predictor
# ==> age now a predictor
# ==> Both sectors increase compensation for directors

# R-squared value


# Plot
plot(m2r2$rsq)
median(m2r2$rsq$rsquared) # R-squared ~ .089 ==> sometimes returns 0.5 but only after updating using update_posterior() ????
quantile(m2r2$rsq$rsquared, c(0.025, 0.25, 0.5, 0.75, 0.975)) # 95% CCI [.46, .54]

# Posterior predictive checks
m2ppc <- dirmod2 %>%
  evaluate_ppc(return_samples=TRUE)

# Residual plot
errs <- data.frame(
  "residuals_model" = resid(dirmod2),
  "predicted_model" = predict(dirmod2),
  "company" = directors$Company
)

library(ggplot2)
p1 <- ggplot(errs, aes(x=predicted_model, y=residuals_model, color=as.factor(company))) +
  geom_point() +
  theme_blm() +
  theme(legend.position="none")
library(purrr)
rc <- errs %>%
  split(.$company) %>%
  map(function(x) {
    x$residuals_lagged <- c(NA, x$residuals_model[1:length(x$residuals_model)-1])
    cor(x$residuals_model, x$residuals_lagged, use="complete.obs")
  }) %>%
  unlist()

rc <- data.frame(
  "cor" = unname(rc),
  "comp" = names(rc)
)

p2 <- ggplot(rc, aes(x=reorder(comp, -abs(cor)), y=cor)) +
  geom_bar(stat="identity") +
  theme_blm() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank()) # ==> correlation by boards, should do a multilevel model here to accomodate hierarchical structure of the data.

library(gridExtra)
grid.arrange(p1, p2, ncol=2)
# Summary
summary(m2ppc$ppc)
p <- plot(m2ppc$ppc, "normality") ; plot(p) # Two-sided test ==> violation ==> less skewed compared to model 1
p <- plot(m2ppc$ppc, "heteroskedasticity") ; plot(p) # One-sided test ==> violation (data are more heteroskedastic) ==> more extreme than model 1
p <- plot(m2ppc$ppc, "independence") ; plot(p) # Two-sided test ==> violation (data are correlated) ==> less extreme than model 1 so we're better taking into account group effects

## Autocorrelation ==> not strange. Board members of the same COMPANY are more alike than board members of other company. Hence the correlation in the errors.

# Model fit
dirmod2 %>%
  evaluate_model_fit() # ==> DIC is 487.895 with 6 parameters ==> fit is better than model 1
```

From figure XX and the posterior predictive checks, we observe that the data are not independent. That is, directors who are in the same board tend to are more similar to each other than directors from other boards. This is not unexpected: the data are hierarchical in nature such that individuals are nested in boards. Indeed, the results of the random effects model shows that the intra-class correlation coefficient $\rho$ equals $57\%$, meaning that the expected correlation of two randomly picked directors from the same company is $\hat{r}=.573$.^[The results of running all different stages of a multilevel model are presented in another document.] 

```{r MLM intercept-only model}
# Jags data
dir_jags <- with(directors, list(## Outcome for individuals (level 1)
  
                                 compensation = Compensation,
                                 # Age of individuals
                                 age=Age,
                                 # Gender of individuals
                                 gender=Male,
                                 
                                 ## Company-level variables (level 2)
                                 
                                 # Company indicator
                                 company=as.numeric(as.factor(Company)),
                                 
                                 ## Group totals
                                 
                                 # Number of individuals
                                 n=nrow(directors),  
                                 # Number of companies
                                 k=length(unique(Company))))

# Intercept-only model
io_mod <- "model {

  ### Level 2 ==> companies

	# Priors (companies)
	tau_u0 ~ dgamma(.01, .01)
	# Hyperprior for mean
  gamma_00 ~ dnorm(0, 1.0E-4)
  # For each company
	for (j in 1:k) {
	  # For each company, draw from normal
    b0[j] ~ dnorm(gamma_00, tau_u0)
	}

	### Level 1 ==> individuals

  # Priors
  # Individual precision
	tau ~ dgamma(.01, .01)  # standard deviation of fixed effect (variance within sectors)
  # For each individual
	for (i in 1:n) {
		compensation[i] ~ dnorm(mu[i], tau) # Combine likelihood and priors
		mu[i] <- b0[company[i]] # Linear combination for each person
	}

  # Invert gamma
  sigma_e <- 1 / sqrt(tau)
  sigma_u0 <- 1 / sqrt(tau_u0)

}"

# Run the model in JAGS
# Initial values
dir_inits <- list(
  init1 <- list(tau=runif(1), tau_u0=runif(1)),
  init2 <- list(tau=runif(1), tau_u0=runif(1))
)

# Specify model in JAGS
mod_io <- jags.model(textConnection(io_mod), 
                     data = dir_jags,
                     inits = dir_inits,
                     n.chains=2)

# Burn
update(mod_io, n.iter=60000)

# Draw samples
params <- c("sigma_e", "sigma_u0", "gamma_00")
# Run the chain
resm1 <- coda.samples(mod_io, variable.names = params, n.iter=500000, thin = 10)

# Convergence?
plot(resm1)

# DIC
DICm1 <- dic.samples(mod_io, thin=5, n.iter=20000, type="pD")

# MAP values
MAPm1 <- apply(do.call(rbind.data.frame, resm1), 2, mean)

# Coerce to matrix
resmat <- do.call(rbind, resm1)

# New matrix with same dims
ve <- matrix(0, ncol=1, nrow=nrow(resmat))

# FOr each row
# Posterior distribution of variance explained
for(i in seq_along(1:nrow(resmat))) {
  ve[i,] <- c(resmat[i,3]^2 / sum(resmat[i,-1]^2))
}

quantile(ve, c(0.025, .25, .5, .75, .975))
# VE between .45 and .69
```

The final random effects model is presented in table YY. This model corresponds to the following equation.

$$
\begin{aligned}
\text{compensation}_{ij} =
&\gamma_{00} + u_{0j} + \gamma_{10}\cdot \text{Age}_{ij} + e_{ij}
\end{aligned}
$$

Where $\gamma_{00}$ is the overall intercept and $u_{0j}$ is a company-specific error term. Notice that the fit of this model is much better than that of the previous models, indicating that the multilevel approach seems appropriate.

```{r MLM level-1 predictors}
# Initial values
dir_inits <- list(
  init1 <- list(tau=runif(1), tau_u0=runif(1)),
  init2 <- list(tau=runif(1), tau_u0=runif(1))
)

# Model
mlm_2 <- "model {

  ### Level 2 ==> companies

	# Priors (companies)
	tau_u0 ~ dgamma(.01, .01)
	# Hyperprior for mean
  gamma_00 ~ dnorm(0, 1.0E-4)
  gamma_10 ~ dnorm(0, 1.0E-4)
  # For each company
	for (j in 1:k) {
	  # For each company, draw from normal
    b0[j] ~ dnorm(gamma_00, tau_u0)
	}

	### Level 1 ==> individuals

  # Priors
  # Individual precision
	tau ~ dgamma(.01, .01)  # standard deviation of fixed effect
  # For each individual
	for (i in 1:n) {
		compensation[i] ~ dnorm(mu[i], tau) # Combine likelihood and priors
		mu[i] <- b0[company[i]] + # Intercept
		         gamma_10*age[i] #+ gamma_20*gender[i] # Level 1 variables
	}

  # Invert gamma
  sigma_e <- 1 / sqrt(tau)
  sigma_u0 <- 1 / sqrt(tau_u0)

}"

# Specify model in JAGS
mod_io <- jags.model(textConnection(mlm_2), 
                     data = dir_jags,
                     inits = dir_inits,
                     n.chains=2)

# Burn
update(mod_io, n.iter=60000)

# Draw samples
params <- c("sigma_e", "sigma_u0", "gamma_00", "gamma_10")
# Run the chain
resm2 <- coda.samples(mod_io, variable.names = params, n.iter=500000, thin = 10)

# DIC
DICm2 <- dic.samples(mod_io, thin=5, n.iter=20000, type="pD")

# Calculate variance explained
# MAP values for model 1
MAPm1 <- apply(do.call(rbind.data.frame, resm1), 2, mean)

# Coerce to matrix
resmat <- do.call(rbind, resm2)

# New matrix with same dims
ve_2 <- matrix(0, ncol=2, nrow=nrow(resmat))

# FOr each row
# Posterior distribution of variance explained (pseudo R-squared)
for(i in seq_along(1:nrow(resmat))) {
  ve_2[i,] <- c( ((MAPm1[2] - resmat[i,3]) / MAPm1[2]), # Level 1
               ((MAPm1[3] - resmat[i,4]) / MAPm1[3])) # Level 2
}

# Map values
MAPve <- apply(ve_2, 2, mean) * 100
```

Given that the variable age only explains some $1.3$\% of the variance on level $1$ and $.8$\% of the variance on level $2$, the conclusion is that we do not have the right predictors 

```{r model results (including model fit), eval=FALSE, results='asis'}
# Calculate 95% CCI
CCI1 <- t(apply(get_posterior_samples(dirmod1), 2, quantile, c(0.025, 0.25, 0.5, 0.75, 0.975))[c(1, 5),]) %>% r
ound(., digits=3)
CCI2 <- t(apply(get_posterior_samples(dirmod2), 2, quantile, c(0.025, 0.25, 0.5, 0.75, 0.975))[c(1, 5),]) %>% 
  round(., digits=3)

# Call stargazer
# ==> we use to linear models with the same variables and replace the coefficients / confidence intervals with those of the blm models
s <- capture.output(
        stargazer::stargazer(lm("Compensation ~ Age + Male", data=directors), 
                             lm("Compensation ~ Age + Male + Sector", data=directors),
                           #title = "Results for BLM models", #dep.var.caption = "Compensation",
                           dep.var.labels = "Compensation",
                           type = "latex",
                          # Replace coefficients
                           coef = list(coef(dirmod1), coef(dirmod2)), 
                           ci = TRUE,
                           ci.custom = list(CCI1, CCI2),
                          # Replace se 
                           #se = list(get_posterior_samples(dirmod1) %>% apply(2, sd),
                          #           get_posterior_samples(dirmod2) %>% apply(2, sd)),
                          
                          # Turn these settings off / on
                          p.auto = FALSE, 
                          df=FALSE, 
                          t.auto=FALSE, 
                          intercept.top = TRUE,
                          intercept.bottom = FALSE,
                          header=FALSE,
                          initial.zero = FALSE,
                          keep.stat = c("n", "rsq", "ser"),
                          order = c(1, 5, 4, 3, 2),
                          report = c("cvs"),
                          single.row = FALSE,
                          add.lines = list(c("DIC", 508, 488),
                                           c("Par.",4, 6)))
        )

# Remove line 34
# s <- s[-26]
# # Change standard error
# s[23] <- paste0("Residual standard deviation & ", 
#                 round(mean(get_posterior_samples(dirmod1)[,4]), digits=3),
#                 " & ",
#                 round(mean(get_posterior_samples(dirmod2)[,6]), digits=3),
#                 " \\\\ ")
# # Change R2
# s[22] <- paste0("R$^{2}$ & ", 
#                 round(median(m1r2$rsquared), digits=3),
#                 " & ",
#                 round(median(m2r2$rsquared), digits=3),
#                 "\\\\ ")

# Print table
cat(
  paste0(
    s, collapse = "\n"
  )
)
``` 

\begin{table}[!htbp] \centering 
  \caption{Model results } 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{3}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & \multicolumn{3}{c}{Compensation} \\ 
\\[-1.8ex] & (1) & (2) & (3)\\ 
\hline \\[-1.8ex] 
Constant & 4.991  (4.936, 5.046) & 4.821 (4.732, 4.910) & 4.991 (4.877, 5.110) \\ 
SectorBasic Materials &  & .225 (.079, .370) &  \\ 
SectorServices &  & .292 (.169, .414) &  \\ 
Male & .065 ($-$.085, .215) & .153 (.095, .209) & \\ 
Age & .008 (0.000, .017) & .009 (.001, .017) & 0.001 (.0035, .0155) \\ 
\hline \\[-1.8ex] 
Intercept variance & & & .3992\\
\hline \\[-1.8ex] 
Observations & 336 & 336 & 336 \\
Companies & & & 52 \\
Par. & 4 & 6 & 47 \\ 
DIC & 508 & 488 & 289 \\ 
R$^{2}$ & .021 & .098 & \\ 
Residual Std. Error & .516 & .501 & .3423 \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{3}{r}{Baseline is sector 'Financials'} \\
\end{tabular} 
\end{table}

```{r classical residuals}
plot(predict(dirmod2), resid(dirmod2))
```


```{r r-squared plot, fig.cap="Bayesian R-squared value for model 1 (left) and model 2 (right). The proportion of cases in which the R-squared value of model 2 exceeds that of model 1 is .99", fig.height=2, fig.width=5}
# Plot r-squared
p1 <- dirmod1 %>% get_value("rsq") %>% plot() + theme_blm(text_size = 8) +
  theme(axis.title = element_blank())
p2 <- dirmod2 %>% get_value("rsq") %>% plot() + theme_blm(text_size = 8) +
  theme(axis.title = element_blank())

# Grid
grid.arrange(p1, p2, ncol=2)
```

## Differences in Bayesian and Frequentist inference

```{r effect of prior variance, fig.height=4, fig.width=5, fig.cap="Effect of adjusting the prior variance of the coefficient for variable Male (a) on the posterior distribution (b). The mean is set at M=.17 which represents a 17% increase in compensation for males versus females. Reducing the prior variance represents increased certainty about the estimate of our domain knowledge and weights the information from the data more strongly compared to domain knowledge (c) and (d)."}
# Posterior shrinkage
dirmod3 <- blm("Compensation ~ Sector + Age + Male",
                data=directors) %>%
  # Need to delete posterior when we change settings
  # (only has an effect if posterior already present)
  delete_posterior() %>%
  # Set an informative prior on the coefficients
  # Male (b4) is speculated to have 17% pay increase over women
  set_prior("b4", mu = .17, sd=0.001) %>%
  # Update sampling settings
  set_sampling_options(chains = 2, iterations = 20000,
                       burn = 4000, thinning=3) %>%
  # Set initial values
  # If we draw from the priors the starting values will be too large
  # This is an issue for MH because it takes many more iterations to converge
  set_initial_values(chain_1 = list("b" = c(4, 2, 3, 8, 10), "sigma"= 1),
                     chain_2 = list("b" = c(2, 4, 7, 2, 3), "sigma"=2)) %>%
  # Sample the posterior distribution
  sample_posterior()

# Change prior and run for another 600000 observations
dirmod3 <- dirmod3 %>%
  set_prior("b4", mu = .17, sd=0.01) %>%
  update_posterior(iterations=20000)
# Same
dirmod3 <- dirmod3 %>%
  set_prior("b4", mu = .17, sd=0.1) %>%
  update_posterior(iterations=20000)

# Retrieve posterior samples for male variable, burn and label by prior variance 
library(purrr)
pd <- get_value(dirmod3, "posterior") %>%
  get_value("samples") %>%
  map(function(x) {
    r1 <- x[4001:20000,"Male"]
    r2 <- x[24001:40000, "Male"]
    r3 <- x[44001:60000, "Male"]
    return(
      data.frame(
        "Male" = c(r1, r2, r3),
        "Prior" = factor(c(rep(1, length(r1)),rep(2, length(r2)), rep(3, length(r3))),
                         labels = c("0.001", "0.01", "0.1"))
      )
    )
  }) %>%
  bind_rows()

# Calculate SD by prior
pd_sd <- pd %>%
  group_by(Prior) %>%
  summarize(psd = sd(Male),
            pmn = mean(Male))

# Posterior z-value
zscore <- function(mean, sd, theta) (mean - theta) / sd
z1 <- zscore(pd_sd$pmn[1], pd_sd$psd[1], .17)
z2 <- zscore(pd_sd$pmn[2], pd_sd$psd[2], .17)
z3 <- zscore(pd_sd$pmn[3], pd_sd$psd[3], .17)

# Posterior scaling of sd
ps1 <- pd_sd$psd[1]^2 / as.numeric(levels(pd_sd$Prior)[1])^2 # 841
ps2 <- pd_sd$psd[2]^2 / as.numeric(levels(pd_sd$Prior)[2])^2 # 35
ps3 <- pd_sd$psd[3]^2 / as.numeric(levels(pd_sd$Prior)[3])^2 # 0.53

library(ggplot2)
library(ggpubr)
priorvar <- ggplot(data.frame(
  "Male" = c(rnorm(10000, mean=.17, sd=0.001), 
             rnorm(10000, mean=.17, sd=.01), 
             rnorm(10000, mean=.17, sd=.1)),
  "Prior" = factor(c(rep(1, 10000), rep(2, 10000), rep(3, 10000)), labels = c("0.001", "0.01", "0.1"))
  ),
  aes(x=Male, fill=Prior)) +
  geom_histogram(alpha=0.4, position="identity", color="black") +
  theme_blm() +
  theme(axis.title = element_blank(),
        axis.text.y=element_blank()) +
  scale_fill_brewer(palette = "Set1",
                    name="Prior variance") +
  labs(title = "(a) Prior distribution")

# Posterior distribution
postvar <- ggplot(pd, aes(x=Male, fill=Prior)) +
  geom_histogram(alpha=0.4, position="identity", color="black") +
  theme_blm() +
  theme(axis.title = element_blank(),
        axis.text.y=element_blank()) +
  scale_fill_brewer(palette = "Set1") +
  labs(title= "(b) Posterior distribution")

# Shift
closeup <- data.frame(
  "value" = c(pd$Male[pd$Prior == "0.01"],rnorm(32000, mean=.17, sd=.01)),
  "type" = c(rep("posterior", 32000), rep("prior", 32000))
)
library(latex2exp)
posteriorshift <- ggplot(closeup, aes(x=value, group=type, fill=type)) +
  geom_histogram(alpha=0.1, position="identity", color="black") +
  # Error bar for prior
  geom_errorbarh(aes(xmin=unname(quantile(closeup$value[closeup$type == "prior"], 0.025)),
                     xmax=unname(quantile(closeup$value[closeup$type == "prior"], 0.975)),
                     y = -600)) +
  annotate(geom="text", x=.13, y=-600, label=TeX("$95% CCI (prior)$"), hjust=.5) +
  # Error bar for posterior
  geom_errorbarh(aes(xmin=unname(quantile(closeup$value[closeup$type == "posterior"], 0.025)),
                     xmax=unname(quantile(closeup$value[closeup$type == "posterior"], 0.975)),
                     y = -1500)) +
  annotate(geom="text", x=pd_sd$pmn[2], y=-2200, label=TeX("$95% CCI (posterior)$")) +
  # Line for prior
  geom_segment(aes(x=.17,xend=.17, y=0, yend=19400), linetype="dashed", color="black",
             size = 0.35) +
  annotate(geom="text", x=.19, y=20000, label=TeX("$\\mu_{prior}$")) +
  # Line for posterior
  geom_segment(aes(x=pd_sd$pmn[2],xend=pd_sd$pmn[2], y=0, yend=19400), linetype="dashed", color="black",
             size = 0.35) +
  annotate(geom="text", x=pd_sd$pmn[2]-.05, y=20000, label=TeX("$\\mu_{posterior}$")) +
  theme_blm() +
  theme(axis.title = element_blank(),
      axis.text.y=element_blank(),
      legend.position = "none") +
  labs(title = "(c) Prior/posterior comparison",
       subtitle = "For prior with variance 0.01")
  
# Text table
tab <- ggtexttable(round(data.frame(
  "prior_var" = c(0.001, 0.01, 0.1),
  "z_score" = c(z1, z2, z3),
  "shrinkage" = c(ps1, ps2, ps3)
), digits=3), rows=NULL, theme=ttheme("minimal"))

# Arrange plots with common legend
ggarrange(priorvar, postvar, posteriorshift, tab, ncol=2, nrow=2, common.legend=TRUE, legend="top")
```

The effect of changing the prior variance can be summarized using a posterior shrinking factor (CITE BETANCOURT) and posterior z-score. The shrinking factor shows us the factor by which the variance of the posterior distribution shrinks or expands compared to the prior variance. The posterior z-score tells us the direction and magnitude by which the posterior mean shifts compared to the prior mean; if we are confident in the precision of our domain knowledge (resulting in small prior variance), the resulting posterior weights this information strongly and we end up with a posterior mean that lies closer to the prior mean (represented by the z-score). However, given that we have small variance, and if this is not corroborated by the data, then the shrinkage factor will be large. 

## Other material

```{r ppc simulations, fig.cap="Distributions of posterior predictive p-values for 1.000 simulated data sets. In plots (a) and (b), the simulated data are drawn from a normal without any violations of the linear regression assumptions. In plot (c), the assumption of homoskedasticity is violated in each of the simulations. In plot (d), the assumption of independence of errors is violated in each of the simulations. The color indicates the severity of the violation; the green bars indicate mild violation, blue indicates medium violation and red indicates severe violation. The script used to generate the data and run the simulations may be found here.", fig.width=5, fig.height=3}

# Convenience function to flatten array
flatten_array <- function(x) {
  
  # To list and return
  lapply(1:dim(x)[3], function(y) {
    ss <- x[,,y]
    colnames(ss) <- c("normality", "heteroskedasticity", "independence")
    # To df
    ss <- as.data.frame(ss)
    # Return
    return(ss)
  })
  
}

# Read data
normal <- readRDS("data/ppc_normal_data.rds")
finsim <- readRDS("data/final.rds")
heterosked <- finsim$heterosked$results %>% 
  flatten_array() %>%
  bind_rows(.id="severity") %>%
  mutate(severity = factor(severity, labels = finsim$heterosked$degrees %>% names()))
indep <- finsim$indep$results %>% 
  flatten_array() %>%
  bind_rows(.id="severity") %>%
  mutate(severity = factor(severity, labels = finsim$heterosked$degrees %>% names()))

# PPC heteroskedasticity, no violation
p1 <- ggplot(data.frame(x=normal[,2]), aes(x=x)) +
  geom_histogram(color="black", fill="lightgrey") +
  scale_x_continuous(limits=c(0,1)) + 
  theme_blm(text_size = 10) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_blank()) +
  labs(title = "(a) PPC heteroskedasticity", subtitle="      no violations")
# PPC independence, no violation
p2 <- ggplot(data.frame(x=normal[,3]), aes(x=x)) +
  geom_histogram(color="black", fill="lightgrey") +
  scale_x_continuous(limits=c(0,1)) + 
  theme_blm(text_size = 10) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_blank()) +
  labs(title = "(b) PPC independence", subtitle="      no violations")
# PPC heteroskedasticity, assumption violated
p3 <- ggplot(heterosked, aes(x=heteroskedasticity, fill=severity)) +
  geom_histogram(color="black", alpha=0.4, position = "identity")  + 
  theme_blm(text_size = 10) + 
  scale_fill_brewer(palette = "Set1", direction=-1) +
  scale_x_continuous(limits=c(-0.02,1)) +
  theme(axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      axis.text.y = element_blank(),
      legend.position = "none") +
  labs(title = "(c) PPC heteroskedasticity", subtitle="      assumption violated")
# PPC independence, violated
p4 <- ggplot(indep, aes(x=independence, fill=severity)) +
  geom_histogram(color="black", alpha=0.4, position = "identity")  + 
  scale_fill_brewer(palette = "Set1", direction=-1) +
  scale_x_continuous(limits=c(-0.02,1)) +
  theme_blm(text_size = 10) +
    theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        legend.position = "none") +
  labs(title = "(d) PPC independence", subtitle="      assumption violated")

# Merge plots
grid.arrange(p1, p2, p3, p4)
```

# References

Lynch, S. M. (2007). Introduction to applied Bayesian statistics and estimation for social scientists. Springer Science & Business Media. Chapter 9.2

Aarts, E. (2019). Introduction to multilevel analysis and the basic two-level regression model, week 1 notes [powerpoint presentation]. *Introduction to Multilevel Analysis*, Utrecht University.
